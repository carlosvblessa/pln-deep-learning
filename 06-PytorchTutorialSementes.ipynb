{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867e09aa",
   "metadata": {},
   "source": [
    "# Classificação de sementes com PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de717dd4",
   "metadata": {},
   "source": [
    "Exploramos um fluxo completo de classificação multiclasse usando o dataset de sementes, desde o pré-processamento até a avaliação final. O foco está em comparar políticas de taxa de aprendizado (schedulers) e observar como afetam a convergência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543392e",
   "metadata": {},
   "source": [
    "O conjunto de dados reúne atributos físicos de três cultivares de trigo. Vamos padronizar as features, treinar uma rede totalmente conectada e monitorar o comportamento em dados de treino, validação e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ec74e",
   "metadata": {},
   "source": [
    "### Definir seeds para reprodutibilidade\n",
    "Sincronizamos os geradores pseudoaleatórios de Python, NumPy e PyTorch (CPU/GPU) e ajustamos o backend cuDNN para minimizar variações entre execuções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42  # valor único usado por todas as bibliotecas\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Evita heurísticas não determinísticas do cuDNN\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27999bba",
   "metadata": {},
   "source": [
    "### Carregar os dados\n",
    "Lemos o arquivo `sementes.csv` localmente e fazemos uma inspeção inicial para conferir o schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a9f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'sementes.csv'\n",
    "try:\n",
    "    dados = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    csv_path = 'sementes.csv'  # fallback mantido para compatibilidade\n",
    "    dados = pd.read_csv(csv_path)\n",
    "\n",
    "dados.head()  # pré-visualiza algumas linhas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ac3e0",
   "metadata": {},
   "source": [
    "Os atributos numéricos descrevem área, perímetro, compacidade e outras medidas que ajudam a distinguir as cultivares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221be27c",
   "metadata": {},
   "source": [
    "### Separar features e rótulos\n",
    "Preparamos arrays independentes: os 7 atributos contínuos em `X` e a classe alvo em `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe51dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados.drop(['Espécie'], axis=1).values  # matrizes de features\n",
    "y = dados['Espécie'].values  # vetor de rótulos\n",
    "X[:3], y[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797306b1",
   "metadata": {},
   "source": [
    "### Criar conjuntos de treino e teste\n",
    "Dividimos os dados preservando a proporção de cada classe em ambos os subconjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "len(X_treino), len(X_teste)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342372e1",
   "metadata": {},
   "source": [
    "### Padronizar as features\n",
    "Ajustamos `StandardScaler` apenas nos dados de treino e reaplicamos ao conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21281798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_treino = scaler.fit_transform(X_treino)  # fit e transform apenas no treino\n",
    "X_teste = scaler.transform(X_teste)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db6cc5",
   "metadata": {},
   "source": [
    "### Converter arrays para tensores\n",
    "Transformamos as matrizes em tensores `float` e `long`, compatíveis com o PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_treino = torch.FloatTensor(X_treino)\n",
    "X_teste  = torch.FloatTensor(X_teste)\n",
    "y_treino = torch.LongTensor(y_treino)\n",
    "y_teste  = torch.LongTensor(y_teste)\n",
    "\n",
    "X_treino.shape, y_treino.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca93a2",
   "metadata": {},
   "source": [
    "### Definir a rede neural\n",
    "Usamos duas camadas ocultas com ReLU e dropout para balancear capacidade e regularização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053857cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Modelo(nn.Module):\n",
    "    def __init__(self, entrada=7, camada_escondida1=14, camada_escondida2=49, saida=3, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(entrada, camada_escondida1)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_p)\n",
    "        self.fc2 = nn.Linear(camada_escondida1, camada_escondida2)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p)\n",
    "        self.out = nn.Linear(camada_escondida2, saida)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)  # remove ativações aleatórias durante o treino\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ddb269",
   "metadata": {},
   "source": [
    "A arquitetura é simples, mas suficiente para observar o impacto de diferentes políticas de taxa de aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54afe02c",
   "metadata": {},
   "source": [
    "### Validação cruzada estratificada\n",
    "Rodamos 5 dobras como diagnóstico para garantir que a arquitetura não dependa de uma única partição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "fold_scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n",
    "    scaler_fold = StandardScaler()\n",
    "    X_train_fold = scaler_fold.fit_transform(X[train_idx])\n",
    "    X_val_fold = scaler_fold.transform(X[val_idx])\n",
    "\n",
    "    X_train_tensor = torch.FloatTensor(X_train_fold)\n",
    "    y_train_tensor = torch.LongTensor(y[train_idx])\n",
    "    X_val_tensor = torch.FloatTensor(X_val_fold)\n",
    "    y_val_tensor = torch.LongTensor(y[val_idx])\n",
    "\n",
    "    modelo_fold = Modelo()\n",
    "    otimizador_fold = torch.optim.Adam(modelo_fold.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    funcao_objetivo_fold = nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(80):  # poucas épocas já sinalizam estabilidade entre as dobras\n",
    "        modelo_fold.train()\n",
    "        logits_train = modelo_fold(X_train_tensor)\n",
    "        custo = funcao_objetivo_fold(logits_train, y_train_tensor)\n",
    "\n",
    "        otimizador_fold.zero_grad()\n",
    "        custo.backward()\n",
    "        otimizador_fold.step()\n",
    "\n",
    "    modelo_fold.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_val = modelo_fold(X_val_tensor).argmax(dim=1)\n",
    "        acc_val = (preds_val == y_val_tensor).float().mean().item()\n",
    "        fold_scores.append(acc_val)\n",
    "        print(f'Dobra {fold}: acurácia = {acc_val:.4f}')\n",
    "\n",
    "print(f'Acurácia média (±dp): {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537bc8e2",
   "metadata": {},
   "source": [
    "### Função de treino com políticas de LR\n",
    "Centralizamos o laço de treinamento para testar diferentes schedulers sem duplicar código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "funcao_objetivo = nn.CrossEntropyLoss()\n",
    "\n",
    "def treinar_modelo(epocas=40, lr=0.01, weight_decay=1e-4, scheduler_tipo=None, scheduler_params=None):\n",
    "    scheduler_params = scheduler_params or {}\n",
    "    modelo = Modelo()\n",
    "    otimizador = torch.optim.Adam(modelo.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Instancia o scheduler solicitado (ou mantém LR constante)\n",
    "    if scheduler_tipo == 'step':\n",
    "        step_size = scheduler_params.get('step_size', max(epocas // 4, 1))\n",
    "        gamma = scheduler_params.get('gamma', 0.5)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(otimizador, step_size=step_size, gamma=gamma)\n",
    "    elif scheduler_tipo == 'cosine':\n",
    "        T_max = scheduler_params.get('T_max', epocas)\n",
    "        eta_min = scheduler_params.get('eta_min', lr / 50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(otimizador, T_max=T_max, eta_min=eta_min)\n",
    "    elif scheduler_tipo == 'reduce_on_plateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            otimizador,\n",
    "            factor=scheduler_params.get('factor', 0.5),\n",
    "            patience=scheduler_params.get('patience', 10),\n",
    "            min_lr=scheduler_params.get('min_lr', 1e-5)\n",
    "        )\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    historico = {\n",
    "        'loss_treino': [],\n",
    "        'loss_teste': [],\n",
    "        'acc_treino': [],\n",
    "        'acc_teste': [],\n",
    "        'lr': [],\n",
    "        'melhor_acc_teste': 0.0,\n",
    "        'melhor_epoca': 0\n",
    "    }\n",
    "\n",
    "    melhor_acc = -1.0\n",
    "    melhor_epoca = 0\n",
    "    melhor_state = None\n",
    "\n",
    "    for epoca in range(epocas):\n",
    "        modelo.train()\n",
    "        otimizador.zero_grad()\n",
    "        logits_treino = modelo(X_treino)\n",
    "        custo_treino = funcao_objetivo(logits_treino, y_treino)\n",
    "        custo_treino.backward()\n",
    "        otimizador.step()\n",
    "\n",
    "        modelo.eval()\n",
    "        with torch.no_grad():\n",
    "            logits_treino = modelo(X_treino)\n",
    "            preds_treino = logits_treino.argmax(dim=1)\n",
    "            acc_treino_epoca = (preds_treino == y_treino).float().mean().item()\n",
    "\n",
    "            logits_teste = modelo(X_teste)\n",
    "            loss_teste = funcao_objetivo(logits_teste, y_teste).item()\n",
    "            preds_teste = logits_teste.argmax(dim=1)\n",
    "            acc_teste_epoca = (preds_teste == y_teste).float().mean().item()\n",
    "\n",
    "        historico['loss_treino'].append(custo_treino.item())\n",
    "        historico['loss_teste'].append(loss_teste)\n",
    "        historico['acc_treino'].append(acc_treino_epoca)\n",
    "        historico['acc_teste'].append(acc_teste_epoca)\n",
    "        historico['lr'].append(float(otimizador.param_groups[0]['lr']))\n",
    "\n",
    "        if acc_teste_epoca > melhor_acc:\n",
    "            melhor_acc = acc_teste_epoca\n",
    "            melhor_epoca = epoca + 1\n",
    "            melhor_state = copy.deepcopy(modelo.state_dict())  # guarda melhor checkpoint\n",
    "\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(loss_teste)  # depende da perda de validação\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "    if melhor_state is not None:\n",
    "        modelo.load_state_dict(melhor_state)\n",
    "\n",
    "    historico['melhor_acc_teste'] = float(melhor_acc)\n",
    "    historico['melhor_epoca'] = int(melhor_epoca)\n",
    "    return modelo, historico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829a2c7",
   "metadata": {},
   "source": [
    "### Comparar estratégias de taxa de aprendizado\n",
    "Executamos o treinamento por 40 épocas usando quatro políticas de LR e registramos o histórico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b26622",
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = 40\n",
    "\n",
    "estrategias = {\n",
    "    'Constante (Adam 0.01)': {'scheduler_tipo': None, 'scheduler_params': {}},\n",
    "    'StepLR (20, gamma=0.5)': {'scheduler_tipo': 'step', 'scheduler_params': {'step_size': 20, 'gamma': 0.5}},\n",
    "    'CosineAnnealing (eta_min=1e-3)': {'scheduler_tipo': 'cosine', 'scheduler_params': {'T_max': epocas, 'eta_min': 1e-3}},\n",
    "    'ReduceLROnPlateau (patience=10)': {'scheduler_tipo': 'reduce_on_plateau', 'scheduler_params': {'factor': 0.5, 'patience': 10, 'min_lr': 1e-4}}\n",
    "}\n",
    "\n",
    "resultados = {}\n",
    "for nome, cfg in estrategias.items():\n",
    "    modelo, historico = treinar_modelo(\n",
    "        epocas=epocas,\n",
    "        lr=0.01,\n",
    "        weight_decay=1e-4,\n",
    "        scheduler_tipo=cfg['scheduler_tipo'],\n",
    "        scheduler_params=cfg.get('scheduler_params')\n",
    "    )\n",
    "    resultados[nome] = {\n",
    "        'modelo': modelo,\n",
    "        'historico': historico,\n",
    "        'config': cfg\n",
    "    }\n",
    "    print(f\"{nome}: melhor acc teste = {historico['melhor_acc_teste']:.4f} (época {historico['melhor_epoca']})\")\n",
    "\n",
    "melhor_nome = max(resultados, key=lambda chave: resultados[chave]['historico']['melhor_acc_teste'])\n",
    "modelo_classificacao = resultados[melhor_nome]['modelo']\n",
    "historico_melhor = resultados[melhor_nome]['historico']\n",
    "print(f\"Melhor estratégia: {melhor_nome} com acc teste {historico_melhor['melhor_acc_teste']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2182a8",
   "metadata": {},
   "source": [
    "### Visualizar perdas, acurácia e LRs\n",
    "Comparamos as trajetórias temporais de cada estratégia para entender padrões de convergência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48218682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "epocas_range = range(1, epocas + 1)\n",
    "\n",
    "for i, (nome, dados) in enumerate(resultados.items()):\n",
    "    hist = dados['historico']\n",
    "    cor = plt.cm.tab10(i % 10)\n",
    "    destaque = 2.5 if nome == melhor_nome else 1.2\n",
    "    alpha = 1.0 if nome == melhor_nome else 0.6\n",
    "\n",
    "    axes[0].plot(epocas_range, hist['loss_treino'], color=cor, linewidth=destaque, alpha=alpha, label=nome)\n",
    "    if nome == melhor_nome:\n",
    "        axes[0].plot(epocas_range, hist['loss_teste'], color=cor, linewidth=1.5, alpha=0.8, linestyle='--', label=f\"{nome} - loss teste\")\n",
    "\n",
    "    axes[1].plot(epocas_range, hist['acc_teste'], color=cor, linewidth=destaque, alpha=alpha, label=nome)\n",
    "    if nome == melhor_nome:\n",
    "        axes[1].scatter(\n",
    "            hist['melhor_epoca'],\n",
    "            hist['melhor_acc_teste'],\n",
    "            color=cor,\n",
    "            edgecolor='white',\n",
    "            linewidth=0.8,\n",
    "            s=80,\n",
    "            zorder=5\n",
    "        )\n",
    "\n",
    "    axes[2].plot(epocas_range, hist['lr'], color=cor, linewidth=destaque, alpha=alpha, label=nome)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Época')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "axes[0].set_title('Loss (treino)')\n",
    "axes[0].set_ylabel('Loss')\n",
    "\n",
    "axes[1].set_title('Acurácia (teste)')\n",
    "axes[1].set_ylabel('Acurácia')\n",
    "axes[1].set_ylim(0.7, 1.02)\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "axes[2].set_title('Taxa de aprendizado')\n",
    "axes[2].set_ylabel('LR')\n",
    "axes[2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388ce5f5",
   "metadata": {},
   "source": [
    "O agendamento constante (Adam 0.01) continua dominante: atinge cerca de 0,93 de acurácia de teste por volta da época 35 e mantém a perda em queda. Os schedulers que reduzem agressivamente o LR estabilizam a curva mais cedo, mas não ultrapassam 0,88–0,90 de acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c4994",
   "metadata": {},
   "source": [
    "### Relatório de métricas no conjunto de teste\n",
    "Imprimimos a estratégia vencedora, estatísticas detalhadas e guardamos a matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544da00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f'Estratégia utilizada: {melhor_nome}')\n",
    "print(f\"Acurácia (melhor época {historico_melhor['melhor_epoca']}): {historico_melhor['melhor_acc_teste']:.4f}\")\n",
    "melhor_lr = historico_melhor['lr'][historico_melhor['melhor_epoca'] - 1]\n",
    "print(f'Taxa de aprendizado nessa época: {melhor_lr:.4e}')\n",
    "print()\n",
    "\n",
    "modelo_classificacao.eval()\n",
    "with torch.no_grad():\n",
    "    logits = modelo_classificacao(X_teste)\n",
    "    preds = logits.argmax(dim=1)\n",
    "\n",
    "df = pd.DataFrame({'Y': y_teste.numpy(), 'YHat': preds.numpy()})\n",
    "df['Correto'] = (df['Y'] == df['YHat']).astype(int)\n",
    "acc = df['Correto'].mean()\n",
    "\n",
    "print(f'Acuracia no teste: {acc:.4f}')\n",
    "print(classification_report(df['Y'], df['YHat'], labels=[0, 1, 2],\n",
    "                               target_names=['Classe 0', 'Classe 1', 'Classe 2']))\n",
    "\n",
    "matriz_confusao = confusion_matrix(df['Y'], df['YHat'])\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d8699",
   "metadata": {},
   "source": [
    "A estratégia constante preserva a melhor acurácia de teste (~0,93) sem depender de reduções de LR. As métricas por classe mostram desempenho equilibrado, com `precision` e `recall` acima de 0,9 para as classes 1 e 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011cd49b",
   "metadata": {},
   "source": [
    "### Matriz de confusão\n",
    "O mapa de calor evidencia onde ainda ocorrem trocas entre cultivares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff96258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "im = ax.imshow(matriz_confusao, cmap='Blues')\n",
    "classes = ['Classe 0', 'Classe 1', 'Classe 2']\n",
    "ax.set_xticks(range(len(classes)))\n",
    "ax.set_yticks(range(len(classes)))\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticklabels(classes)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "for i in range(matriz_confusao.shape[0]):\n",
    "    for j in range(matriz_confusao.shape[1]):\n",
    "        ax.text(j, i, matriz_confusao[i, j], ha='center', va='center', color='black')\n",
    "\n",
    "ax.set_xlabel('Predito')\n",
    "ax.set_ylabel('Verdadeiro')\n",
    "ax.set_title('Matriz de confusão')\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a5b7e",
   "metadata": {},
   "source": [
    "Os erros concentram-se na Classe 0, onde 3 amostras foram rotuladas como Classe 2. As classes 1 e 2 ficaram sem enganos, indicando que decisões de fronteira ainda podem ser refinadas para a Classe 0 (coletar mais dados ou ajustar pesos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f1292",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Modelo parece sólido: o scheduler constante chegou a ~0,93 de acurácia de teste, mantida estável após a época 35, e as métricas por classe ficaram equilibradas, com precision/recall ≥0,9 para as classes 1 e 2. A matriz de confusão mostra apenas alguns erros na Classe 0 e sem confusões nas demais, sinal de generalização boa para um dataset compacto.\n",
    "\n",
    "Quanto a overfitting, os sinais são leves: as curvas de loss e acurácia não se separam drasticamente, não há queda de performance de teste ao longo das 40 épocas e usamos dropout/weight decay, o que ajuda a conter sobreajuste. Ainda existe risco por causa do volume pequeno de dados (apenas três erros na Classe 0), então valeria monitorar com validação cruzada ou coletar mais exemplos se quiser robustez maior, mas no estado atual o modelo está bem comportado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
